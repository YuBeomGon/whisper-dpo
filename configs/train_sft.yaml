model_name: openai/whisper-tiny
train_dataset: data/dpo_triplets/zeroth_train.jsonl
eval_dataset: data/dpo_triplets/zeroth_test.jsonl
output_dir: outputs/sft/1021/whisper_tiny_zeroth
language: ko
task: transcribe
per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 5e-6
num_train_epochs: 1
logging_steps: 100
evaluation_strategy: steps
eval_steps: 500
save_steps: 500
save_total_limit: 2
gradient_checkpointing: false
seed: 42
fp16: true
hf_home: .cache/huggingface
report_to:
  - tensorboard
